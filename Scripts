## for replacing ">" in the aceession number with ">speciesname" and "|" with "_" using sed for the ease of identifaction that sequnce belongs to which species.

#!/bin/bash

#SBATCH --partition=defq                                              #using defq for the quick and small jobs
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=50g
#SBATCH --time=10:00:00
#SBATCH --job-name=replace_accession_query sequence                   #change job name
#SBATCH --output=/gpfs01/home/mbxss25/slurm-%x-%j.out                 #replace with your username
#SBATCH --mail-type=ALL
#SBATCH --mail-user=mbxss25@exmail.nottingham.ac.uk                   #replace with your username

# Directory containing your TXT files
input_dir="/mbxss25/data/dom/selected_genes"                  #path of directory where file are stored conating accession numbers
output_dir="/mbxss25/data/dom/query_seqs"                             #path of directory where you wish to store new files.
mkdir -p "$output_dir"                                                # Ensure the output directory exists

# Process each .txt file in the directory
for file in "$input_dir"/*.txt; do
    # Extract the base filename without the extension    
    base_filename=$(basename "$file" .txt)
    
    # Construct the output filename
    output_file="$output_dir/${base_filename}.txt"

    # Process the file and write to the output directory
    sed -e "s/>/>${base_filename}_/" -e 's/|/_/g' "$file" > "$output_file"
    
    echo "Processed and output to $output_file"
done

echo "All files have been processed."

Input file: 1. selected_genes.zip
Output directory: 2. query_seqs.zip

Note: zip files are uploaded only because of github limitation. Original file does not have .zip extention.
------------------------------------------------------------------------------------------------------------------------------------------------------
## for replacing ">" in the aceession number with ">speciesname" and "|" with "_" using sed for the ease of identifaction that sequnce belongs to which species.

#!/bin/bash

#SBATCH --partition=defq                                              #using defq for the quick and small jobs
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=50g
#SBATCH --time=10:00:00
#SBATCH --job-name=replace_accession                                  #change job name
#SBATCH --output=/gpfs01/home/mbxss25/slurm-%x-%j.out                 #replace with your username
#SBATCH --mail-type=ALL
#SBATCH --mail-user=mbxss25@exmail.nottingham.ac.uk                   #replace with your username

# Directory containing your TXT files
input_dir="/mbxss25/data/dom/subject_dborg"                  #path of directory where file are stored conating accession numbers
output_dir="/mbxss25/data/dom/subject_db"                             #path of directory where you wish to store new files.
mkdir -p "$output_dir"                                                # Ensure the output directory exists

# Process each .txt file in the directory
for file in "$input_dir"/*.txt; do
    # Extract the base filename without the extension    
    base_filename=$(basename "$file" .txt)
    
    # Construct the output filename
    output_file="$output_dir/${base_filename}.txt"

    # Process the file and write to the output directory
    sed -e "s/>/>${base_filename}_/" -e 's/|/_/g' "$file" > "$output_file"
    
    echo "Processed and output to $output_file"
done

echo "All files have been processed."

Input file: 3_subject_dborg.zip
Output directory: 4_subject_db.zip

Note: zip files are uploaded only because of github limitation. Original file does not have .zip extention.
------------------------------------------------------------------------------------------------------------------------------------------------------------------
# To translate the DNA sequnces into amino acids, using biopython.

from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
import sys
import os

def translate_dna(input_file, output_file):
    records = SeqIO.parse(input_file, "fasta")
    protein_records = []

    for record in records:
        seq_length = len(record.seq)
        trim_length = seq_length - (seq_length % 3)
        trimmed_seq = record.seq[:trim_length]
        protein_seq = trimmed_seq.translate()
        protein_record = SeqRecord(protein_seq, id=record.id, description="translated sequence")
        protein_records.append(protein_record)

    SeqIO.write(protein_records, output_file, "fasta")

def ensure_directory_exists(output_dir):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

def process_files(input_path, output_dir):
    ensure_directory_exists(output_dir)
    
    if os.path.isdir(input_path):
        # Process each file in the directory
        for filename in os.listdir(input_path):
            file_path = os.path.join(input_path, filename)
            if filename.endswith(".txt"):  # Ensure processing only text files
                output_file = os.path.join(output_dir, filename.replace('.txt', '_protein.fasta'))
                translate_dna(file_path, output_file)
                print(f"Translated {file_path} to {output_file}")
    elif os.path.isfile(input_path):
        # Process a single file
        if input_path.endswith(".txt"):  # Ensure processing only text files
            filename = os.path.basename(input_path)
            output_file = os.path.join(output_dir, filename.replace('.txt', '_protein.fasta'))
            translate_dna(input_path, output_file)
            print(f"Translated {input_path} to {output_file}")

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: python script.py <input_path> <output_dir>")
        sys.exit(1)
    
    input_path = sys.argv[1]
    output_dir = sys.argv[2]
    
    process_files(input_path, output_dir)

----------------------------------------------------
#to run above python script for translation

#!/bin/bash

#SBATCH --partition=defq
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=50g
#SBATCH --time=10:00:00
#SBATCH --job-name=DNA_AA_translation
#SBATCH --output=/gpfs01/home/mbxss25/slurm-%x-%j.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=mbxss25@exmail.nottingham.ac.uk

input_dir="subject_db"
output_dir="aa_data"

python ./translate.py "$input_dir" "$output_dir"

output file: 5_aa_data.zip
---------------------------------------------------------
#to merge all the translated sequnces in single fasta file.

#!/bin/bash

#SBATCH --partition=defq
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=50g
#SBATCH --time=10:00:00
#SBATCH --job-name=merging_aa
#SBATCH --output=/gpfs01/home/mbxss25/slurm-%x-%j.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=mbxss25@exmail.nottingham.ac.uk

# Define the directory containing your FASTA files
directory="./aa_data"

# Define the output file where the merged FASTA will be saved
output_file="./aa_merged_x"

# Ensure the output file is empty
> "$output_file"

# Loop through all FASTA files in the specified directory, sorted alphabetically
for file in $(find "$directory" -name '*.fasta' | sort); do
    echo "Merging $file into $output_file"
    # Optionally, you can add a newline before each new file's content to ensure no run-ons from previous files
    echo "" >> "$output_file"
    cat "$file" >> "$output_file"
done

echo "All FASTA files have been merged into $output_file"

Output file: 6_merged_all_aminoacids.fasta.zip
---------------------------------------------------------
